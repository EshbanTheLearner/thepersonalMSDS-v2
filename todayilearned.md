# Today I Learned (TIL)

**Caution: This timeline is tailored for @EshbanTheLearner and might not be suitable for everyone.**

## Part - I (13 January 2020 to 22 April 2020)

### Day 82 | April 4, 2020 | Saturday

**Today's Progress:** Today I studied about **Reinforcement Learning for Stock Trading**

**Description:** This includes the following:
- Intro to Reinforcement Learning
- Deep Q-Learning
- Defining States
  - Time Series (Fixed Window)
  - Cash in Hand
  - Buying Current Stocks to Buy Better Stocks
- Defining Actions
  - Buy/Sell/Hold Stock
  - For N stocks, 3^N possibilities
  - How many stocks to sell/buy?
- Simplified Actions
  - Ignore Transaction Costs
  - Avoid Knapsack Problem
  - Buy Multiple Stocks in Round Robin Fashion
  - Sell before Buy
- Defining Rewards
  - Portfolio Value
- Minimal Trading Bot Implementation in Tensorflow 2.0

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)


### Day 81 | April 3, 2020 | Friday

**Today's Progress:** Today I studied about **Recommendation Systems**

**Description:** This includes the following:
- Introduction
- Content Based Methods
- Collaborative Filtering Methods
  - Model Based
    - Matrix Facorization
  - Memory Based
    - Item Centered Bayesian Classifier
    - User Centered Linear Regression
- Hybrid Methods
- Evaluation of Recommendation Systems
  - Metric Based Evaluation
  - Human Based Evaluation
- Deep Learning for Recommendation Systems
  - Embeddings
- Simple Movie Recommender System (TensorFlow 2.0)

**Important Links:**
 
[Article 1 | Introduction to Recommender Systems](https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada)

[Article 2 | Recommender Systems in Practice](https://towardsdatascience.com/recommender-systems-in-practice-cef9033bb23a)

[Article 3 | Recommender Systems with Deep Learning Architectures](https://towardsdatascience.com/recommender-systems-with-deep-learning-architectures-1adf4eb0f7a6)

[Article 4 | RecSys Series Part 2: The 10 Categories of Deep Recommendation Systems That Academic Researchers Should Pay Attention To](https://towardsdatascience.com/recommendation-system-series-part-2-the-10-categories-of-deep-recommendation-systems-that-189d60287b58)

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)


### Day 80 | April 2, 2020 | Thursday

**Today's Progress:** Today I completed the **Bash Scripting, Linux and Shell Programming Complete Guide** on Udemy.

**Description:** This includes the following:
- Bash Scripting
  - Bash File Structure
  - Echo Command
  - Comments
  - Variables
  - Strings
  - Loops
    - While
    - For
    - Until
    - Break & Continue
  - User Input
  - Conditional Statements
  - Case Statements
  - Command Line Arguments
  - Functions
    - Global vs Local Variables
  - Arrays
  - Shell & Environment Variables
  - Scheduled Automation
  - Aliases
  - Wildcards
  - Multiple Commands

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 79 | April 1, 2020 | Wednesday

**Today's Progress:** Today I continued with the **Bash Scripting, Linux and Shell Programming Complete Guide** on Udemy.

**Description:** This includes the following:
- Users
  - Run Commands as Superuser
  - Change User
  - Show Effecter User and Group IDs
- Killing Programs and Logging Out
  - Kill A Running Command
  - Kill All Processes By a Name
  - Logging Out of Bash 
- Shortcuts
  - No More Input
  - Clear Screen
  - Zoom In
  - Zoom Out
  - Moving the Cursor
  - Deleting Text
  - Fixing Typos
  - Cutting and Pasting
  - Character Capitalization

### Day 78 | March 31, 2020 | Tuesday

**Today's Progress:** Today I continued with the **Bash Scripting, Linux and Shell Programming Complete Guide** on Udemy.

**Description:** This includes the following:
- Getting Help
  - Show Manual Description
  - Search Manual
  - Reference Manuals
- Working with Files/Folders
  - Creating a Folder
  - Creating a File
  - Copy Files/Folders
  - Move and Rename File/Folders
  - Delete Files/Folders
  - Delete Empty Folders
  - Change File Permission
- Text Files
  - File Concatenation
  - File Perusal Filter
  - Terminal Based Text Editor

### Day 77 | March 30, 2020 | Monday

**Today's Progress:** Today I started the **Bash Scripting, Linux and Shell Programming Complete Guide** on Udemy.

**Description:** This includes the following:
- Introduction
  - Bash/Shell
  - Terminal
  - Shell
  - Console
- Navigation
  - Listing Folder Contents
  - Print Current Folder
  - Change Folder
  - Using a Stack to Push Folders
  - Check File Type
  - Find File By Name & Update Locate Database
  - Find a Command
  - Show Command History

**Important Links:** 
[Udemy | Bash Scripting, Linux and Shell Programming Complete Guide](https://www.udemy.com/course/bash-scripting-course/)


### Day 76 | March 29, 2020 | Sunday

**Today's Progress:** Today I completed the **Modernizing Data Lakes and Data Warehouses with GCP** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 2: Module 2**
  - BigQuery as a Data Warehousing Solution
    - Exploring Schemas
    - Schema Design
    - Nested and Repeated Fields
  - **Lab 4 (BigQuery: JSON and Array Data):**
    - Loading semi-structured JSON into BigQuery
    - Creating and querying arrays
    - Creating and querying structs
    - Querying nested and repeated field
  - Partitioning and Clustering in BigQuery
    - Optimizing with Partitioning and Clustering
    - Creating Partitioned Tables
    - Partitioning and Clustering
    - Transforming Batch and Streaming Data

[Certificate | Modernizing Data Lakes and Data Warehouses with GCP](https://www.coursera.org/account/accomplishments/verify/79FC83QD7N9B)

### Day 75 | March 28, 2020 | Saturday

**Today's Progress:** Today I continued with the **Modernizing Data Lakes and Data Warehouses with GCP** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 2: Module 1**
  - Building a Data Warehouse
    - The Modern Data Warehouse
    - Intro to BigQuery
    - Querying TBs of Data in Seconds
    - Loading Data
  - **Lab 3 (BigQuery):**
    - Loading Data into BigQuery

### Day 74 | March 27, 2020 | Friday

**Today's Progress:** Today I continued with the **Modernizing Data Lakes and Data Warehouses with GCP** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 1: Module 2**
  - Building a Data Lake
    - Intro to Data Lakes
    - Data Storage and ETL options on GCP
    - Optimizing Cost with Google Cloud Storage classes and Cloud Functions
    - Securing Cloud Storage
    - Storing All Sorts of Data Types
    - Running Federated Queries on Parquet and ORC files in BigQuery
    - Storing Relational Data in the Cloud
    - Cloud SQL as a Relational Data Lake
  - **Lab 1 (Cloud SQL):**
    - Loading Data into Cloud SQL

### Day 73 | March 26, 2020 | Thursday

**Today's Progress:** Today I enrolled in the **Modernizing Data Lakes and Data Warehouses with GCP** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 1: Module 1**
  - Role of Data Engineer
  - Data Engineering Challenges
  - Intro to BigQuery
  - Data Lakes and Data Warehouses
  - Transactional Databases vs Data Warehouses
  - Effective Partnership with Other Data Teams
    - Manage Data Access and Governance
    - Build Production-Ready Pipelines
  - GCP Customer Case Study
    - Ocado
  - **Lab 1 (Analysis with BigQuery):**
    - Analyze 2 different public datasets 
    - Run queries on them, to derive interesting insights
      - Separately 
      - Combined

[Coursera | Data Engineering with Google Cloud Professional Certificate](https://www.coursera.org/professional-certificates/gcp-data-engineering) 

[Coursera | Modernizing Data Lakes and Data Warehouses with GCP](https://www.coursera.org/learn/data-lakes-data-warehouses-gcp)

### Day 72 | March 25, 2020 | Wednesday

**Today's Progress:** Today I continued with the **Google Cloud Platform Big Data and Machine Learning Fundamentals** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 2: Module 2**
  - ML Driving Business Value
  - ML on Unstructred Data
  - Choosing the Right ML Approach
    - Pre-Built AI Building Blocks
    - Using Pre-Built AI to Create a Chatbot
    - Customizing Pre-Built Models with AutoML
    - Building a Custom Model
  - **Lab 5 (AutoML)**
    - Setup API key for ML Vision API
    - Invoke the pretrained ML Vision API to classify images
    - Review label predictions from Vision API
    - Train and evaluate custom AutoML Vision image classification model
    - Predict with AutoML on new image

[Certificate | Google Cloud Platform Big Data and Machine Learning Fundamentals](https://www.coursera.org/account/accomplishments/verify/VXNTJABLUQEH)

### Day 71 | March 24, 2020 | Tuesday

**Today's Progress:** Today I continued with the **Google Cloud Platform Big Data and Machine Learning Fundamentals** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 2: Module 1**
  - Modern Data Pipeline Challenges
  - Message-Oriented Architectures
  - Serverless Data Pipelines
    - Designing Streaming Pipelines with Apache Beam
    - Implementing Streaming Pipelines on Cloud DataFlow
  - Data Visualization with Data Studio
    - Building Collaborative Dashboards
    - Tips and Tricks to create Charts with the Data Studio UI
  - **Lab 4 (Data Streaming Pipeline)**
    - Connect to a streaming data Topic in Cloud Pub/sub
    - Ingest streaming data with Cloud Dataflow
    - Load streaming data into BigQuery
    - Analyze and visualize the results

### Day 70 | March 23, 2020 | Monday

**Today's Progress:** Today I continued with the **Google Cloud Platform Big Data and Machine Learning Fundamentals** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 1: Module 3**
  - Introduction to BigQuery
    - Fast SQL Query Engine
    - Managed Storage for Datasets
  - Insights from Geographic Data
  - Machine Learning on Structured Data
    - Choosing the right model type
    - Scenario: Predicting Customer Lifetime Value
  - Creating ML Models with SQL
    - Introduction to BigQuery ML
    - ML Projects Phases
    - Key Features Walkthrough
  - **Lab 3 (BigQuery ML)**
    - Use BigQuery to find public datasets
    - Query and explore the ecommerce dataset
    - Create a training and evaluation dataset to be used for batch prediction
    - Create a classification (logistic regression) model in BQML
    - Evaluate the performance of your machine learning model
    - Predict and rank the probability that a visitor will make a purchase

### Day 69 | March 22, 2020 | Sunday

**Today's Progress:** Today I continued with the **Google Cloud Platform Big Data and Machine Learning Fundamentals** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 1: Module 2**
  - Recommendation Systems
    - Data
    - Model
    - Training/Serving Infrastructure
  - Google Storage Systems
    - Cloud Storage
    - Cloud SQL
    - Cloud Spanner
    - DataStore
    - BigTable
    - BigQuery
  - Hadoop Ecosystem
    - Hadoop
    - Hive
    - Pig
    - Spark
  - **Lab 2 (Recommendation System)**
    - Create Cloud SQL instance
    - Create database tables by importing .sql files from Cloud Storage
    - Populate the tables by importing .csv files from Cloud Storage
    - Allow access to Cloud SQL
    - Explore the rentals data using SQL statements from CloudShell

### Day 68 | March 21, 2020 | Saturday

**Today's Progress:** Today I enrolled in the **Google Cloud Platform Big Data and Machine Learning Fundamentals** course of **Data Engineering with Google Cloud Professional Certificate** on Coursera.

**Description:** This includes the following:
- **Week 1: Module 1**
  - Google Cloud Architecture
    - Security
      - Google IAM
    - Compute Power
      - On Demand VMs
    - Storage
      - Multiregional
      - Regional
      - Nearline
      - Coldline
    - Networking
      - Edge Computing/Node/PoP
    - Big Data/ ML Products
      - GFS
      - MapReduce
      - BigTable
      - Dremel
      - Pub/Sub
      - Tensorflow etc
  - **Lab 1 (BigQuery)**
    - Query a public dataset
    - Create a custom table
    - Load data into a table
    - Query a table
  - GCP Approaches
    - Compute Engine
    - Google Kubernetes Engine (GKE)
    - App Engine
    - Cloud Functions
  - Business Use Cases w/ GCP

**Important Links:**
[Coursera | Data Engineering with Google Cloud Professional Certificate](https://www.coursera.org/professional-certificates/gcp-data-engineering) 

[Coursera | Google Cloud Platform Big Data and Machine Learning Fundamentals](https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-engineering)

### Day 67 | March 20, 2020 | Friday

**Today's Progress:** Today I ended and reviewd the **Time Series Analysis in Python 2020** course on udemy.

**Description:** I learned following things:
- Differentiate between time series data and cross-sectional data.
- Understand the fundamental assumptions of time series data and how to take advantage of them.
- Transforming a data set into a time-series.
- Start coding in Python and learn how to use it for statistical analysis.
- Carry out time-series analysis in Python and interpreting the results, based on the data in question.
- Examine the crucial differences between related series like prices and returns.
- Comprehend the need to normalize data when comparing different time series.
- Encounter special types of time series like White Noise and Random Walks.
- Learn about "autocorrelation" and how to account for it.
- Learn about accounting for "unexpected shocks" via moving averages.
- Discuss model selection in time series and the role residuals play in it.
- Comprehend stationarity and how to test for its existence.
- Acknowledge the notion of integration and understand when, why and how to properly use it.
- Realize the importance of volatility and how we can measure it.
- Forecast the future based on patterns observed in the past.

### Day 66 | March 19, 2020 | Thursday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- Business Case: Automobile Industry
  - Analysing the data leading up to the Volkswagen buyout of Porsche
  - In Retrospect Approach
  - The Dieselgate Scandal
  - Auto ARIMA
  - Predictions using Exogenous Variables
  - Measuring Volatility
  - GARCH

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 65 | March 18, 2020 | Wednesday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- Forecasting
  - Forecast vs Prediction
  - Forecasting Time Series:
    - ARMA
    - ARIMA
    - ARIMAX
    - SARIMA
    - SARIMAX
    - GARCH
  - Pitfalls of Forecasting
  - Multivariate Forecasting 

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 64 | March 17, 2020 | Tuesday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- The Auto ARIMA Model
  - The Auto AutoRegressive Integrated Moving Average (ARIMA) Model
    - Manual vs Automatic Empirical Analysis
    - Pros & Cons
  - Fitting Default Best Fit Auto ARIMA Model
  - Auto ARIMA with Custom Arguments
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 63 | March 16, 2020 | Monday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- The ARCH Model
  - The AutoRegressive Conditional Heteroskedasticity (ARCH) Model
  - Volatility
    - EGARCH
  - Fitting a Simple ARCH Model
  - Fitting Higher Lag ARCH Model
  - Generalized AutoRegressive Conditional Heteroskedasticity (GARCH) Model
    - Volatility Clustering
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 62 | March 15, 2020 | Sunday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- The ARIMA Model
  - The AutoRegressive Integrated Moving Average (ARIMA) Model
  - Fitting a Simple ARIMA Model
  - Fitting Higher-Lag ARIMA Model
  - Higher Levels of Integration
  - Outdide Factors
    - Exogeneous Variables
    - ARMAX
    - ARIMAX
  - Seasonal Models
    - SARMA
    - SARIMA
    - SARIMAX
  - Predicting Stability
    - Volatility & Variance
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 61 | March 14, 2020 | Saturday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- The ARMA Model
  - The AutoRegressive Moving Average (ARMA) Model
  - Fitting a Simple ARMA Model
  - Fitting Higher-Lag ARMA Model
  - Examining the ARMA Model Residuals
  - ARMA Models and Non-Stationary Data
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 60 | March 13, 2020 | Friday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- Adjusting to Shocks The MA Model
  - Moving Average (MA) Model
  - Fitting the MA Model
  - Fitting Higher-Lag MA Model
  - Examining the MA Model Residuals
  - Model Selection for Normalized Returns
  - Past Values and Past Errors
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 59 | March 12, 2020 | Thursday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- Modelling AutoRegression
  - AR Model
  - ACF & PACF
  - Dicky-Fuller Test
  - LLR Test
  - Error Analysis w/ Residuals
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 58 | March 11, 2020 | Wednesday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- Picking the Correct Model
  - Significant Coefficients
  - Parsimonious
    - Log-Liklihood Ratio Test
    - AIC & BIC
  - Residuals

### Day 57 | March 10, 2020 | Tuesday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- Working with Time Series in Python
  - White Noise
    1. Constant Mean
    2. Constant Variance
    3. No Autocorrelation
  - Random Walk
    - Market Efficiency
    - Arbitrage
  - Stationary
    - Covariance Stationary
      1. Constant Mean
      2. Constant Variance
      3. Consistent Covariance b/w different Time Periods
    - Determining Weak Form Stationary
      1. Dickey-Fuller Test
  - Seasonality
    - Decomposition
      - Trend
      - Seasonal
      - Residual
    - Naive Decomposition
      1. Additive
      2. Multiplicative
  - Autocorrelation
    - AutoCorrelation Function (ACF)
    - Partial AutoCorrelation Function (PACF)
  - Python Implementation

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)


### Day 56 | March 9, 2020 | Monday

**Today's Progress:** Today I continued the **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- Creating a Time Series Object
  - Transforming String Inputs into DateTime Values
  - Using Date as an Index
  - Setting the Frequency
  - Filling Missing Values
  - Adding and Removing Columns in DataFrame
  - Splitting Up the Data
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 55 | March 8, 2020 | Sunday

**Today's Progress:** Today I enrolled in **Time Series Analysis in Python 2020** course on udemy.

**Description:** This includes the following:
- Introduction
- Setting Up the Environment
- Introduction to Time Series in Python
    - Time Periods
    - Frequency
    - Pattern Persistance
    - Notations in Time-Series
    - Peculiarities of Time Series
    - Implementation in Python
      - Loading Data
      - Exploring Data
      - Visulaizing Data
      - QQ Plot

**Important Links:** 
[Udemy | Time Series Analysis in Python 2020](https://www.udemy.com/course/time-series-analysis-in-python/)

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 54 | March 7, 2020 | Saturday

**Today's Progress:** Today I ended and reviewed with **Python for Finance: Investment Fundamentals & Data Analytics** course on udemy.

**Description:** This includes the following:
- Rate of return of stocks 
- Risk of stocks 
- Rate of return of stock portfolios 
- Risk of stock portfolios 
- Correlation between stocks 
- Covariance 
- Diversifiable and non-diversifiable risk 
- Regression analysis
- Alpha and Beta coefficients
- Measuring a regression’s explanatory power with R^2
- Markowitz Efficient frontier calculation
- Capital asset pricing model
- Sharpe ratio
- Multivariate regression analysis
- Monte Carlo simulations
- Using Monte Carlo in a Corporate Finance context
- Derivatives and type of derivatives
- Applying the Black Scholes formula
- Using Monte Carlo for options pricing
- Using Monte Carlo for stock pricing

### Day 53 | March 6, 2020 | Friday

**Today's Progress:** Today I continued with **Python for Finance: Investment Fundamentals & Data Analytics** course on udemy.

**Description:** This includes the following:
- **Part 17: Monte Carlo Simulations as a decision-making Tool**
  - Monte Carlo Simulations
  - Monte Carlo in Corporate Finance Setting
    - Revenues
    - Cost of Goods Sold
    - Gross Profit
    - Cogs & Opex
  - Asset Pricing with Monte Carlo
    - Brownian Motion
      1. Drift
      2. Volatility
  - Derivative Contracts
    - Assets
      1. Stocks
      2. Bonds
      3. Interest Rates
      4. Commodities
      5. Exchange Rates
    - Groups of Derivatives
      1. Hedging
      2. Speculating
      3. Aribtrageurs
    - Types of Derivatives
      1. Forwards
      2. Futures
      3. Swaps
      4. Options
        - Call Options vs Put Options
  - The Black Scholes Formula
    - Efficient Markets
    - Transaction Costs
    - No Divided Payments
    - Known Volatility & Risk-Free
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 52 | March 5, 2020 | Thursday

**Today's Progress:** Today I continued with **Python for Finance: Investment Fundamentals & Data Analytics** course on udemy.

**Description:** This includes the following:
- **Part 16: Multivariate Regression Analysis**
  - Fundamentals of Multivariate Regression
    - Higher Dimensions
    - R-Squared
    - P-Value
    - Beta Coefficients
  - Implementation in Python

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 51 | March 4, 2020 | Wednesday

**Today's Progress:** Today I continued with **Python for Finance: Investment Fundamentals & Data Analytics** course on udemy.

**Description:** This includes the following:
- **Part 15: The Capital Asset Pricing Model**
  - The Capital Asset Pricing Model
    - Market Portfolio
    - Risk Free Asset
    - Beta Coefficient
    - Capital Market Line
    - Market Risk Premium
  - Sharpe Ratio
  - Achieving Alpha
  - Types of Investment Strategies
    - Passive Investing
    - Active Investing
    - Arbitrage Trading
    - Value Investing
  - Implementation in Python
    - Calculating Beta of a Stock
    - Calculating CAPM of a Stock
    - Calculating Sharpe Ratio

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 50 | March 3, 2020 | Tuesday

**Today's Progress:** Today I continued with **Python for Finance: Investment Fundamentals & Data Analytics** course on udemy.

**Description:** This includes the following:
- **Part 14: Markowitz Portfolio Optimization**
  - Markowitz Portfolio Theory
    - Single Investment vs Diversified Potfolio
    - Markowitz Efficient Frontier
  - Implementation in Python
    - Calculating Expected Portfolio Return
    - Calculating Expected Portfolio Variance
    - Calculating Expected Portfolio Volatility
    - Calculating Markowitz Efficient Frontier

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 49 | March 2, 2020 | Monday

**Today's Progress:** Today I continued with **Python for Finance: Investment Fundamentals & Data Analytics** course on udemy.

**Description:** This includes the following:
- **Part 13: Using Regression for Financial Analysis**
  - Fundamental of Simple Regression
    1. Univariate Regression
    2. Multivariate Regression
  - Good vs Bad Regression
    - R-squared
  - Implementation in Python
    - Running Regression model for House Price Data
    - Calculating:
      1. Slope (beta)
      2. Intercept (alpha)
      3. R Value
      4. R-squared Value
      5. P Value
      6. Standard Error

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 48 | March 1, 2020 | Sunday

**Today's Progress:** Today I continued with **Python for Finance: Investment Fundamentals & Data Analytics** course on udemy.

**Description:** This includes the following:
- Implementation in Python
  - Calculating Simple Rate of Return
  - Calculating Log Rate of Return
  - Calculating Rate of Return of Indices
  - Calculating Risk of a Security
    - Variance
    - Correlation
    - Volatility
  - Calculating Risk of an Investment Portfolio
    - Calculating Diversifiable and Non-Diversifiable Risk

[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)

### Day 47 | February 29, 2020 | Saturday

**Today's Progress:** Today I enrolled in **Python for Finance: Investment Fundamentals & Data Analytics** course on udemy.

**Description:** This includes the following:
- **Part 1-10: Python Refresher**
  - *Skipped*
- **Part 11: Calculating and Comparing Rates of Return**
  - Rate of Return of Stocks
    - Simple Returns
    - Log Returns
  - Rate of Return of Stock Portfolios
    - Market Indices
      1. S&P500
      2. Dow Jones Industrial Average
      3. NASDAQ
- **Part 12: Measuring Investment Risk**
  - Risk of Stocks
    - Variability
      1. Variance
      2. Standard Deviation
  - Risk of Stock Portfolios
    - Portfolio Diversification
    - Covariance
    - Correlation
    - Un-diversifiable (Systematic) Risk vs Diversifiable (Idiosyncratic) Risk

**Important Links:** 
[Udemy | Python for Finance: Investment Fundamentals & Data Analytics](https://www.udemy.com/course/python-for-finance-investment-fundamentals-data-analytics/)

### Day 46 | February 28, 2020 | Friday

**Today's Progress:** Today I ended and reviewed the **Artificial Intelligence for Business** course on Udemy.
- OPTIMIZE BUSINESS PROCESSES
  - Implement Q-Learning
  - Build an Optimization Model
  - Maximize Efficiency
- MINIMIZE COSTS
  - Implement Deep Q-Learning
  - Build an AI Environment from scratch
  - Build an Artificial Brain
  - Master the General AI Framework
  - Save and Load a model
  - Implement Early Stopping
- MAXIMIZE REVENUES
  - Implement Thompson Sampling
  - Leverage AI to make the best decision
  - Implement Online Learning
  - Implement Regret Analysis

### Day 45 | February 27, 2020 | Thursday

**Today's Progress:** Today I continued with the **Artificial Intelligence for Business** course on udemy.

**Description:** This includes the following:
- **Part-3: Maximizing Revenue**
  - AI Solution
    - The Multi-Armed Bandit Problem
    - Thompson Sampling
  - Implementation in Python

### Day 44 | February 26, 2020 | Wednesday

**Today's Progress:** Today I continued with the **Artificial Intelligence for Business** course on udemy.

**Description:** This includes the following:
- **Part-3: Maximizing Revenue**
  - Case Study: *Maximizing Revenue of an Online Retail Business*
    - Problem to Solve
    - Environment to Define
      1. Defining States
      2. Defining Actions
      3. Defining Reward Function

### Day 43 | February 25, 2020 | Tuesday

**Today's Progress:** Today I continued with the **Artificial Intelligence for Business** course on udemy.

**Description:** This includes the following:
- **Part-2: Minimizing Costs**
  - Case Study: *Minimizing Costs in Energy Consumption of a Data Center*
    - Problem to Solve
    - Environment to Define
      1. Defining States
      2. Defining Actions
      3. Defining Reward Function
  - AI Solution
    - Deep Q-Learning: Intuition
    - Deep Q-Learning: Action
    - Experience Replay
    - Action Selection Policies
  - Implementation in Python

### Day 42 | February 24, 2020 | Monday

**Today's Progress:** Today I enrolled in **Artificial Intelligence for Business** course on udemy.

**Description:** This includes the following:
- Introduction to Course
- **Part-1: Optimizing Business Process**
  - Case Study: *Optimizing the Flows in an E-Commerce Warehouse*
    - Problem to Solve
    - Environment to Define
      1. Defining States
      2. Defining Actions
      3. Defining Reward Function
  - AI Solution
    - Intro to Reinforcement Learning
    - The Bellman Equation
    - The "Plan"
    - Markov Decision Process (MDP)
      1. Deterministic Search
      2. Non-Deterministic Search
    - Policy vs Plan
    - Adding a "Living Penalty"
    - Q-Learning: Intuition
    - Temporal Difference
    - Q-Learning: Visualization
  - Implementation in Python

**Important Links:** 
[Udemy | Artificial Intelligence for Business](https://www.udemy.com/course/ai-for-business/)
[Relevant Codebase](https://github.com/EshbanTheLearner/thepersonalmsds/tree/master/codebase)	

### Day 41 | February 23, 2020 | Sunday

**Today's Progress:** Today I ended and reviewed the **Taming Big Data with Apache Spark and Python - Hands On!** course on Udemy.

**Description:** I learned following skills in this course:
- Use DataFrames and Structured Streaming in Spark 3
- Frame big data analysis problems as Spark problems
- Use Amazon's Elastic MapReduce service to run your job on a cluster with Hadoop YARN
- Install and run Apache Spark on a desktop computer or on a cluster
- Use Spark's Resilient Distributed Datasets to process and analyze large data sets across many CPU's
- Implement iterative algorithms such as breadth-first-search using Spark
- Use the MLLib machine learning library to answer common data mining questions
- Understand how Spark SQL lets you work with structured data
- Understand how Spark Streaming lets your process continuous streams of data in real time
- Tune and troubleshoot large jobs running on a cluster
- Share information between nodes on a Spark cluster using broadcast variables and accumulators
- Understand how the GraphX library helps with network analysis problems

### Day 40 | February 22, 2020 | Saturday

**Today's Progress:** Today I continued the **Taming Big Data with Apache Spark and Python - Hands On!** course on Udemy.

**Description:** This includes the following:
- Other Spark Technologies
- Intro to MLLib
- Using DataFrames with MLLib
- Spark Streaming
- GraphX

### Day 39 | February 21, 2020 | Friday

**Today's Progress:** Today I continued the **Taming Big Data with Apache Spark and Python - Hands On!** course on Udemy.

**Description:** This includes the following:
- Intro to SparkSQL
- DataFrame:
  - Executing SQL commands
  - SQL-style function
- Using DataFrame instead of RDDs

### Day 38 | February 20, 2020 | Thursday

**Today's Progress:** Today I continued the **Taming Big Data with Apache Spark and Python - Hands On!** course on Udemy.

**Description:** This includes the following:
- Elastic MapReduce
- Partitioning
- Troubleshooting Spark on a Cluster
- Managing Dependencies

### Day 37 | February 19, 2020 | Wednesday

**Today's Progress:** Today I continued the **Taming Big Data with Apache Spark and Python - Hands On!** course on Udemy.

**Description:** This includes the following:
- Advance Examples of Spark Programs
  - Activities
    - Finding Most Popular Movie
    - Using Broadcast Variables
- Using Graphs
  - Superhero Degree of Seperation
    - Intro to Breadth-First Search
    - Accumlators, and Implementing BFS in Spark
- Item-Based Collaborative Fillering in Spark
  - cache() and persist()
  - Activity
    - Similar Movie Script using Spark's Cluster Manager

### Day 36 | February 18, 2020 | Tuesday

**Today's Progress:** Today I continued the **Taming Big Data with Apache Spark and Python - Hands On!** course on Udemy.

**Description:** This includes the following:
- Spark Basics and Simple Examples
  - Intro to Spark 
  - Resilient Distributed Dataset (RDD)
  - Key/Value RDDs
    - Example: Average Friends by Age
  - Filtering RDDs
    - Example: Minimum Temperature by Location
    - Example: Maximum Temperature by Location
  - Map vs FaltMap
    - Example: Word Count

### Day 35 | February 17, 2020 | Monday

**Today's Progress:** Today I enrolled in **Taming Big Data with Apache Spark and Python - Hands On!** course on udemy.

**Description:** This includes the following:
- Getting Started with Spark
  - Introduction to course
  - Setting up the Environment
  - Running First Spark Program
    - Ratings Histogram for MovieLens Movie Rating Dataset

**Important Links:** 
- [Udemy | Taming Big Data with Apache Spark and Python - Hands On!](https://www.udemy.com/course/taming-big-data-with-apache-spark-hands-on/)



### Day 34 | February 16, 2020 | Sunday

**Today's Progress:** Today I learned to use the normal distribution as an approximation of the binomial distribution, when appropriate.

**Description:** This includes the following:
- Normal Random Variables
  - Applications 
    - Approximation to Binomial
    - Continuity Correction
- Wrap-Up: Random Variable

### Day 33 | February 15, 2020 | Saturday

**Today's Progress:** Today I learned to explain how a density function is used to find probabilities involving continuous random variables. I also learned to find probabilities associated with the normal distribution.

**Description:** This includes the following:
- Continuous Random Variables
  - Probability Distribution
    - Discrete Random Variable
- Normal Random Variables
  - Standard Deviation Rule
  - Standardizing Values
  - Standard Normal Table
    - Introduction
    - Finding **z** value
    - Working with Non-standard Normal Values
    - Finding **X** value

### Day 32 | February 14, 2020 | Friday

**Today's Progress:** Today I learned to fit the binomial model when appropriate, and use it to perform simple calculations.

**Description:** This includes the following:
- Binomial Random Variables
  - Binomial Experiment
  - Probability Distribution
  - Mean and Standard Deviation

### Day 31 | February 13, 2020 | Thursday

**Today's Progress:** Today I learned how to find the mean and variance of a discrete random variable, and apply these concepts to solve real-world problems. I also learned to apply the rules of means and variances to find the mean and variance of a linear transformation of a random variable and the sum of two independent random variables.

**Description:** This includes the following:
- Discrete Random Variables
  - Mean and Variance
    - Introduction
    - Applications
  - Standard Deviation 
  - Rules for Mean and Variances
    - Add, Subtract, Multiplication by Constant
    - Linear Transformation
    - Sum of Two Variables

### Day 30 | February 12, 2020 | Wednesday

**Today's Progress:** Today I continued on the first course of the Tensorflow: Data and Deployment Specialization.

**Description:** This includes the following:
- **Week 4**
  - Train a model in your web browser by using images captured via a webcam
  - Apply transfer learning to train a model to recognize hand gestures of rock, paper, and scissors
  - Apply transfer learning to train a model to recognize hand gestures of rock, paper, scissors, lizard, and spock

### Day 29 | February 11, 2020 | Tuesday

**Today's Progress:** Today I continued on the first course of the Tensorflow: Data and Deployment Specialization.

**Description:** This includes the following:
- **Week 3**
  - Use a toxicity model to determine if a phrase is toxic in a number of categories
  - Use Mobilenet to detect objects in images
  - Use the tensorflow.js converter to convert a Keras model to JSON format

### Day 28 | February 10, 2020 | Monday

**Today's Progress:** Today I started the first course of the Tensorflow: Data and Deployment Specialization.

**Description:** This includes the following:
- **Week 1**
  - Use TensorFlow.js to build and train simple machine learning models in JavaScript
  - Use Web Server for Chrome to serve web pages from a local folder over the network using HTTP.
  - Describe the key characteristics of one-hot encoding
  - Use TensorFlow.js to load data from a CSV file
- **Week 2**
  - Use tf-vis to visulize the output of callbacks
  - Use a convolutional neural network to build a handwriting classifier
  - Use a sprite sheet to train a classifier

**Important Links:** 
- [Coursera | Browser-based Models with Tensorflow.js](https://www.coursera.org/learn/browser-based-models-tensorflow)

### Day 27 | February 9, 2020 | Sunday

**Today's Progress:** Today I learned to distinguish between discrete and continuous random variables. Also learned to find the probability distribution of discrete random variables, and use it to find the probability of events of interest.

**Description:** This includes the following:
- Discrete Random Variables
  - Random Variables
    - Introduction
    - Count vs Measure
- Probability Distribution
  - Table of Outcomes
  - Probability Histograms
  - Applications
  - Using Conditional Probability


### Day 26 | February 8, 2020 | Saturday

**Today's Progress:** Today I learned to use the General Multiplication Rule to find the probability that two events occur (P(A and B)) and to use probability trees as a tool for finding probabilities.

**Description:** This includes the following:
- Multiplication Rule
  - General Multiplication Rule
    - Definition
    - Applications
- Probability Trees
  - Definition
  - Applications
  - Other Methods
- Wrap-Up: Conditional Probability and Independance

### Day 25 | February 7, 2020 | Friday

**Today's Progress:** Today I learned about the reasoning behind conditional probability, and how this reasoning is expressed by the definition of conditional probability. Also learned to find conditional probabilities and interpret them, and determine whether two events are independent or not.

**Description:** This includes the following:
- Conditional Probability
  - Reasoning
  - Definition
- Independence Check
  - Compare P(B | A) and P(B)
  - Other Methods

### Day 24 | February 6, 2020 | Thursday

**Today's Progress:** Today I learned how to apply probability rules in order to find the likelihood of an event. I also learned to use tools such as Venn diagrams or probability tables as aids for finding probabilities, when appropriate.

**Description:** This includes the following:
- Probability Rules
  - Range and Sum Rules
  - Complement Rule
  - Disjoint Events
  - Addition Rule for Disjoint Events
  - P(A and B) for Independent Events
  - Multiplication Rule for Independent Events
  - Extensions
  - At Least One of...
  - General Addition Rule
  - Probability Tables
    - Solving Problems
- Wrap-Up: Finding Probability of Events

### Day 23 | February 5, 2020 | Wednesday

**Today's Progress:** Today I learned how to determine the sample space of a given random experiment. I also learned to find the probability of events in the case in which all outcomes are equally likely.

**Description:** This includes the following:
- Probability of Events
- Sample Spaces
  - Random Experiments
- Events of Interest
- Equally Likely Outcomes
  - Overview
  - Examples

### Day 22 | February 4, 2020 | Tuesday

**Today's Progress:** Today I learned how to relate the probability of an event to the likelihood of this event occurring.I also learned how relative frequency can be used to estimate the probability of an event.

**Description:** This includes the following:
- Empirical Methods for Determinig Probability
- Verifying Classical Probability
- Relative Frequency
  - Definition
  - Law of Large Numbers

### Day 21 | February 3, 2020 | Monday

**Today's Progress:** Today I learned how to relate the probability of an event to the likelihood of this event occurring.

**Description:** This includes the following:
- Probability
  - Introduction
    - The Bigger Picture
    - Intuition
    - Formal Definition
- Determining Probability
  - Theoritical/Classical
  - Empirical/Observational

### Day 20 | February 2, 2020 | Sunday

**Today's Progress:** Today I learned how to identify the design of a study (controlled experiment vs. observational study) and other features of the study design (randomized, blind etc.).

**Description:** This includes the following:
- Experiments: More than One Explanatory Variable
  - Modification to Randomization
- Wrap-Up: Designing Studies
- Summary: Producing Data

### Day 19 | February 1, 2020 | Saturday

**Today's Progress:** Today I learned how to identify the design of a study (controlled experiment vs. observational study) and other features of the study design (randomized, blind etc.).

**Description:** This includes the following:
- Experiments: One Explanatory Variable
  - Caustaion and Experiments
    - Randomized Controll Experiments
    - Inclusion of a Control Group
  - Blind and Double-Blind Experiments
  - Pitfalls

### Day 18 | January 31, 2020 | Friday

**Today's Progress:** Today I learned how the study design impacts the types of conclusions that can be drawn. Also learned to determine how the features of a survey impact the collected data and the accuracy of the data.

**Description:** This includes the following:
- Observational Studies
  - Caustaion and Observational Studies
    - Lurking Variables
    - Other Pitfalls
  - Design Issues
  - Summary

### Day 17 | January 30, 2020 | Thursday

**Today's Progress:** Today I learned to use Convolutions on top of DNNs and RNNs and then put it all together using a real-world data series -- one which measures sunspot activity over hundreds of years.

**Description:** This includes the following:
- **Week 4:** Real-World Time Series Data
  - Convolutions
  - Bi-Directional LSTMs
  - Batch Sizing
  - Training and Tunning
  - Prediction

**Important Links:** 
- [Certificate | Sequences, Time Series and Prediction](https://www.coursera.org/account/accomplishments/verify/TGGZDVYQQF7F)
- [Certificate | TensorFlow in Practice Specialization](https://www.coursera.org/account/accomplishments/specialization/MCZZWYTTM3QP)

### Day 16 | January 29, 2020 | Wednesday

**Today's Progress:** Having explored time series and some of the common attributes of time series such as trend and seasonality, and then having used statistical methods for projection, today I learned neural networks to recognize and predict on time series. I also learned that Recurrent Neural networks and Long Short Term Memory networks are really useful to classify and predict on sequential data.

**Description:** This includes the following:
- **Week 2:** Deep Neural Networks for Time Series
  - Data Preparation
  - Sequence Bias
  - Feeding Windowed Data to Neural Network
  - Prediction
- **Week 3:** Recurrent Neural Network for Time Series
  - Lambda Layers
  - Dynamically adjusting Learning Rate
  - Huber Loss
  - RNN
  - LSTM

### Day 15 | January 28, 2020 | Tuesday

**Today's Progress:** Today I learned about the nature of time series data, and saw some of the more common attributes of them, including things like seasonality and trend. I also looked at some statistical methods for predicting time series data also.

**Description:** This includes the following:
- **Week 1:** Sequences and Prediction
  - Introduction
  - Common Patterns
    - Trend
    - Seasonality
    - White Noise
    - Autocorrelation
    - Impulses
  - Metrics for Evaluation
    - MSE
    - RMSE
    - MAE
  - Moving Average and Differencing
  - Trailing vs Centered Windows
  - Forecasting

**Important Links:** 
- [Coursera | Sequences, Time Series and Prediction](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction/)

### Day 14 | January 27, 2020 | Monday

**Today's Progress:** Today I learned to use TensorFlow for various Natural Language Processing problems.

**Description:** This includes the following:
- Sentiment in Text
  - Text to Sequence
  - Tokenizer
  - Padding
- Word Embeddings
  - Introduction
  - Vectors
  - Loss Function
  - Pre-Tokenized Datasets
- Sequence Models
  - LSTMs
  - Accuracy and Loss
  - Convolutional Networks
- Sequence Models and Literature
  - Subword Tokenization
  - Text Generation
  - Shakespearean Poetry Generation

**Important Links:** 
- [Coursera | Natural Language Processing in TensorFlow](https://www.coursera.org/learn/natural-language-processing-tensorflow)
- [Certificate | Natural Language Processing in TensorFlow](https://www.coursera.org/account/accomplishments/verify/6GAZVJ6J2HQE)

### Day 13 | January 26, 2020 | Sunday

**Today's Progress:** Today I learned to identify the design of a study (controlled experiment vs. observational study) and other features of the study design (randomized, blind etc.).

**Description:** This includes the following:
- Producing Data: Designing Studies
  - Introduction
  - Types of Studies
    - Experimental Studies
    - Obesrvational Studies
      - Prospective
      - Retrospective


### Day 12 | January 25, 2020 | Saturday

**Today's Progress:** Today I learned various techniques by which one can choose a sample of individuals from an entire population to collect data from. This is seemingly a simple step in the big picture of statistics, but it turns out that it has a crucial effect on the conclusions we can draw from the sample about the entire population.

**Description:** This includes the following:
- Producing Data: Sampling
- Types of Samples
  - Volunteer Sample
  - Convenience Sample
  - Sampling Frame
  - Systematic Sampling
- Probability Sampling Plans
  - Simple Random Sampling
  - Cluster Sampling
  - Stratified Sampling 
- Wrap-Up: Sampling

### Day 11 | January 24, 2020 | Friday

**Today's Progress:** Today I summarized how to explore the relationship between the explanatory and response variables using visual displays and numerical measures, and how to choose what kind of measure to use based on the role-type classification of the two variables. I also emphasized how important it is to interpret any observed association in the context of the problem, but NOT to be tempted to interpret association as causation, due to the possible presence of lurking variables.


**Description:** This includes the following:
- Wrap-Up: Examining Relationships
- Summary: EDA

### Day 10 | January 23, 2020 | Thursday

**Today's Progress:** Today I learned how to recognize the distinction between association and causation, and identify potential lurking variables for explaining an observed relationship. Association **does not** imply causation!

**Description:** This includes the following:
- Causation and Lurking Variables
  - Introduction
  - Confounds
  - Simpson's Paradox

### Day 09 | January 22, 2020 | Wednesday
**Today's Progress:**

**Description:** This includes the following:
- AWS Builders Online Series
  - Introductory Guide to AWS Cost Management and Efficiency
  - Move Fast & Be Secure on AWS Cloud
  - AWS Purpose-Built Database Strategy: The Right Tool for The Right Job
  - Host your Static Website on Amazon Simple Storage Service (S3)
  - Building Serverless Applications that Scale
- Project Management Professional Certification: Introduction


### Day 08 | January 21, 2020 | Tuesday
**Today's Progress:** Today I learned about a special case of the relationship between two quantitative variables is the linear relationship. In this case, a straight line simply and adequately summarizes the relationship. When the scatterplot displays a linear relationship, we supplement it with the correlation coefficient (r). The least-squares regression line has the smallest sum of squared vertical deviations of the data points from the line. Extrapolation is the prediction of values of the explanatory variable that falls outside the range of the data.

**Description:** Following topics were covered:
- Case Q → Q: Linear Relationships
  - Introduction
  - Correlation
    - R - Coefficient of Correlation
    - Properties of R
  - Regression
  - Least Squares Regression
  - Intercept and Slope
  - Predictions

### Day 07 | January 20, 2020 | Monday
**Today's Progress:** Today I learned how to graphically display the relationship between two quantitative variables and describe: a) the overall pattern and b) striking deviations from the pattern.

**Description:** Following topics were covered:
- Case Q → Q
  - Two Quantitative Variables
  - Scatterplots
    - Introduction
    - Interpretation
    - Examples
    - Labeled
    - Exercises

### Day 06 | January 19, 2020 | Sunday
**Today's Progress:** Today I learned about the C → C relationship between two categorical variables. Building a two-way table and interpreting the information stored in it about the association between two categorical variables by comparing conditional percentages.

**Description:** Following topics were covered:
- Case C → C
  - Two Categorical Variables
  - Conditional Percents
  - Exercises

### Day 05 | January 18, 2020 | Saturday
**Today's Progress:** Today I learned about how to examine relationships between 2 variables using visual displays and numerical summaries. 

**Description:** These includes the following topics:
- EDA: Examining Relationships
- Exploring Two Variables: Explanatory and Response
- Role-Type Classification
- Case C → Q
  - Introduction
  - Applications

### Day 04 | January 17, 2020 | Friday
**Today's Progress:** Today I learned that the range covered by the data is the most intuitive measure of spread and is exactly the distance between the smallest data point (min) and the largest one (Max). Another measure of spread is the inter-quartile range (IQR), which is the range covered by the middle 50% of the data. The IQR can be used to detect outliers using the 1.5(IQR) criterion. Outliers are observations that fall below Q1 - 1.5(IQR) or above Q3 + 1.5(IQR). The five-number summary of distribution consists of the median (M), the two quartiles (Q1, Q3) and the extremes (Min, Max). The standard deviation measures the spread by reporting a typical (average) distance between the data points and their average.

**Description:** These includes the following topics:
- One Quantitative Variable: Measure of Spread
  - Range
  - Inter-Quartile Range
    - Using IQR to detect outliers
  - Outliers
    - Identification
    - Understanding
    - Handling
  - Boxplots
  - Standard Deviation
    - Idea
    - Notion
    - Calculation
    - Properties
    - Standard Deviation Rule
- WrapUp: EDA

### Day 03 | January 16, 2020 | Thursday
**Today's Progress:** Learned how to quantify the center and spread of distribution with various numerical measures, some of the properties of those numerical measures; and how to choose the appropriate numerical measures of center and spread to supplement the histogram.

**Description:** This includes the following:
- One Quantitative Variable: Measures of Center
  - Introduction
  - Mode
  - Median
  - Mean
  - Comparison b/w Mean and Median

### Day 02 | January 15, 2020 | Wednesday

**Today's Progress:** Learned about uni-quantitative variables and how to represent it using Histogram and Stemplot. I also learned about how to interpret these graphs for further insights.

**Description:** This includes the following:
- One Quantitative Variable: Graphs
  - Introduction
  - Histogram
    - Intervals
    - Shape
    - Center, Spread, and Outliers
  - Stemplot


### Day 01 | January 14, 2020 | Tuesday

**Today's Progress:** Got a formal intro to statistics, learned about Exploratory Data Analysis and One Categorical Variable

**Description:** This includes the following:
- Introduction to Statistics
- Exploratory Data Analysis Overview
  - Data and Variables
  - Scales of Measurement
  - Examining Distributions
- One Categorical Variable
  - Frequency Distributions
  - Pie and Bar Charts
  - Pictograms

### Pilot | January 13, 2020 | Monday

**Today's Progress:** 

- Setup Repository for #thepersonalmsds
- Created template for Social Media
- Enrolled in Stanford University's Probability & Statistics Course

**Description:** *None*

**Important Links:** [Stanford | Probability & Statistics](https://lagunita.stanford.edu/courses/course-v1:OLI+ProbStat+Open_Jan2017/course/)